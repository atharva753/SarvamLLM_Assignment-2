{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsyXRLN421UsA4Qu4mLEVa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atharva753/SarvamLLM_Assignment-2/blob/main/Optimised_einops.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbmDO9XGz9S1",
        "outputId": "c47fcb8d-a1ad-4e75-d46a-1acdd0ef4e00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "from typing import Dict, List, Tuple, Optional, Union, Any, Set\n",
        "from functools import lru_cache\n",
        "\n",
        "\n",
        "@lru_cache(maxsize=128)\n",
        "def parse_pattern(pattern: str) -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Parse the pattern string and split it into input and output parts.\n",
        "    Uses caching to avoid re-parsing the same patterns.\n",
        "\n",
        "    Args:\n",
        "        pattern: The einops pattern string (e.g., 'b c h w -> b h w c')\n",
        "\n",
        "    Returns:\n",
        "        A tuple of (input_pattern, output_pattern)\n",
        "    \"\"\"\n",
        "    if '->' not in pattern:\n",
        "        raise ValueError(\"Pattern must contain '->' to separate input and output dimensions\")\n",
        "\n",
        "    parts = pattern.split('->')\n",
        "    if len(parts) != 2:\n",
        "        raise ValueError(\"Pattern must contain exactly one '->'\")\n",
        "\n",
        "    input_pattern = parts[0].strip()\n",
        "    output_pattern = parts[1].strip()\n",
        "\n",
        "    return input_pattern, output_pattern\n",
        "\n",
        "\n",
        "# Regex patterns for more efficient parsing\n",
        "COMPOSITE_AXIS_PATTERN = re.compile(r'\\(([\\w\\s]+)\\)')\n",
        "AXIS_PATTERN = re.compile(r'(\\(\\w+(?:\\s+\\w+)*\\)|\\w+|\\.\\.\\.)')\n",
        "\n",
        "\n",
        "@lru_cache(maxsize=128)\n",
        "def parse_axis(axis: str) -> Tuple[str, bool, List[str]]:\n",
        "    \"\"\"\n",
        "    Parse a single axis specification, handling parentheses for merging/splitting.\n",
        "    Uses regex for faster parsing and caching for reuse.\n",
        "\n",
        "    Args:\n",
        "        axis: The axis specification (e.g., '(h w)', 'b', etc.)\n",
        "\n",
        "    Returns:\n",
        "        A tuple of (axis_name, is_composite, components)\n",
        "    \"\"\"\n",
        "    is_composite = axis.startswith('(') and axis.endswith(')')\n",
        "\n",
        "    if is_composite:\n",
        "        # Extract components using regex for better performance\n",
        "        match = COMPOSITE_AXIS_PATTERN.match(axis)\n",
        "        if not match:\n",
        "            raise ValueError(f\"Invalid composite axis format: {axis}\")\n",
        "        inner_content = match.group(1).strip()\n",
        "        components = inner_content.split()\n",
        "        return axis, True, components\n",
        "\n",
        "    return axis, False, [axis]\n",
        "\n",
        "\n",
        "@lru_cache(maxsize=64)\n",
        "def parse_axes(pattern: str) -> List[Tuple[str, bool, List[str]]]:\n",
        "    \"\"\"\n",
        "    Parse all axes in a pattern using regex for better performance.\n",
        "\n",
        "    Args:\n",
        "        pattern: A pattern string (either input or output part)\n",
        "\n",
        "    Returns:\n",
        "        A list of parsed axes\n",
        "    \"\"\"\n",
        "    # Special handling for ellipsis\n",
        "    if '...' in pattern:\n",
        "        parts = pattern.split('...')\n",
        "        if len(parts) != 2:\n",
        "            raise ValueError(\"Pattern can contain at most one ellipsis (...)\")\n",
        "\n",
        "        before_ellipsis = parts[0].strip()\n",
        "        after_ellipsis = parts[1].strip()\n",
        "\n",
        "        # Use regex to extract axes\n",
        "        before_axes = AXIS_PATTERN.findall(before_ellipsis) if before_ellipsis else []\n",
        "        after_axes = AXIS_PATTERN.findall(after_ellipsis) if after_ellipsis else []\n",
        "\n",
        "        parsed_before = [parse_axis(ax) for ax in before_axes]\n",
        "        ellipsis_marker = [('...', False, ['...'])]\n",
        "        parsed_after = [parse_axis(ax) for ax in after_axes]\n",
        "\n",
        "        return parsed_before + ellipsis_marker + parsed_after\n",
        "\n",
        "    # Regular case without ellipsis - use regex for better performance\n",
        "    axes = AXIS_PATTERN.findall(pattern)\n",
        "    return [parse_axis(ax) for ax in axes]\n",
        "\n",
        "\n",
        "def _get_dim_sizes(\n",
        "    input_axes: List[Tuple[str, bool, List[str]]],\n",
        "    tensor_shape: Tuple[int, ...],\n",
        "    axes_lengths: Dict[str, int]\n",
        ") -> Tuple[Dict[str, int], List[int], int]:\n",
        "    \"\"\"\n",
        "    Calculate dimension sizes for all axes in one pass.\n",
        "\n",
        "    Args:\n",
        "        input_axes: Parsed input axes\n",
        "        tensor_shape: Shape of the input tensor\n",
        "        axes_lengths: Dictionary mapping axis names to their lengths\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (dimension dict, ellipsis_dims, ellipsis_len)\n",
        "    \"\"\"\n",
        "    dims_dict = {**axes_lengths}  # Start with provided axes_lengths\n",
        "    tensor_dim_idx = 0\n",
        "    ellipsis_dims = []\n",
        "\n",
        "    for axis, is_composite, components in input_axes:\n",
        "        if axis == '...':\n",
        "            # Calculate how many dimensions are covered by ellipsis\n",
        "            remaining_explicit_dims = sum(1 for ax, _, _ in input_axes if ax != '...')\n",
        "            ellipsis_size = len(tensor_shape) - remaining_explicit_dims\n",
        "\n",
        "            # Store ellipsis dimensions\n",
        "            for j in range(ellipsis_size):\n",
        "                if tensor_dim_idx < len(tensor_shape):\n",
        "                    ellipsis_dims.append(tensor_shape[tensor_dim_idx])\n",
        "                    tensor_dim_idx += 1\n",
        "        elif is_composite:\n",
        "            # For composite axes, get dimension and calculate component sizes\n",
        "            if tensor_dim_idx < len(tensor_shape):\n",
        "                total_size = tensor_shape[tensor_dim_idx]\n",
        "                tensor_dim_idx += 1\n",
        "\n",
        "                # Calculate sizes for components\n",
        "                unknown_components = [c for c in components if c not in dims_dict]\n",
        "\n",
        "                if len(unknown_components) > 1:\n",
        "                    raise ValueError(f\"Multiple unknown components in axis {axis}\")\n",
        "\n",
        "                if unknown_components:\n",
        "                    # Calculate size for the single unknown component\n",
        "                    known_product = 1\n",
        "                    for c in components:\n",
        "                        if c in dims_dict:\n",
        "                            known_product *= dims_dict[c]\n",
        "\n",
        "                    if known_product == 0:\n",
        "                        raise ValueError(f\"Cannot infer size for {unknown_components[0]}, product of known sizes is 0\")\n",
        "\n",
        "                    if total_size % known_product != 0:\n",
        "                        raise ValueError(f\"Total size {total_size} not divisible by known components product {known_product}\")\n",
        "\n",
        "                    dims_dict[unknown_components[0]] = total_size // known_product\n",
        "                else:\n",
        "                    # Verify all components have correct sizes\n",
        "                    component_product = 1\n",
        "                    for c in components:\n",
        "                        component_product *= dims_dict[c]\n",
        "\n",
        "                    if component_product != total_size:\n",
        "                        raise ValueError(\n",
        "                            f\"Product of component sizes {component_product} doesn't match axis size {total_size}\"\n",
        "                        )\n",
        "        else:\n",
        "            # For simple axes, use the tensor dimension size\n",
        "            if tensor_dim_idx < len(tensor_shape):\n",
        "                dims_dict[axis] = tensor_shape[tensor_dim_idx]\n",
        "                tensor_dim_idx += 1\n",
        "\n",
        "    return dims_dict, ellipsis_dims, len(ellipsis_dims)\n",
        "\n",
        "\n",
        "def _compute_transpose_and_shapes(\n",
        "    input_axes: List[Tuple[str, bool, List[str]]],\n",
        "    output_axes: List[Tuple[str, bool, List[str]]],\n",
        "    tensor_shape: Tuple[int, ...],\n",
        "    dims_dict: Dict[str, int],\n",
        "    ellipsis_dims: List[int],\n",
        "    ellipsis_len: int\n",
        ") -> Tuple[List[int], List[int], List[int]]:\n",
        "    \"\"\"\n",
        "    Compute intermediate reshape, transpose, and final reshape in one pass.\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (initial_shape, transpose_indices, final_shape)\n",
        "    \"\"\"\n",
        "    # First calculate the initial reshape (splitting composite axes)\n",
        "    initial_shape = []\n",
        "    axis_positions = {}\n",
        "    pos = 0\n",
        "\n",
        "    for axis, is_composite, components in input_axes:\n",
        "        if axis == '...':\n",
        "            # Add ellipsis dimensions\n",
        "            for i, dim in enumerate(ellipsis_dims):\n",
        "                initial_shape.append(dim)\n",
        "                axis_positions[f\"..._{i}\"] = pos\n",
        "                pos += 1\n",
        "        elif is_composite:\n",
        "            # Add component dimensions for composite axes\n",
        "            for component in components:\n",
        "                if component not in dims_dict:\n",
        "                    raise ValueError(f\"Size for component '{component}' not found\")\n",
        "                initial_shape.append(dims_dict[component])\n",
        "                axis_positions[component] = pos\n",
        "                pos += 1\n",
        "        else:\n",
        "            # Add dimension for simple axis\n",
        "            initial_shape.append(dims_dict[axis])\n",
        "            axis_positions[axis] = pos\n",
        "            pos += 1\n",
        "\n",
        "    # Now calculate the transposition order\n",
        "    transpose_indices = []\n",
        "    ellipsis_positions = [axis_positions[f\"..._{i}\"] for i in range(ellipsis_len)]\n",
        "\n",
        "    for axis, is_composite, components in output_axes:\n",
        "        if axis == '...':\n",
        "            # Add all ellipsis positions in order\n",
        "            transpose_indices.extend(ellipsis_positions)\n",
        "        elif is_composite:\n",
        "            # Add positions for all components\n",
        "            for component in components:\n",
        "                if component not in axis_positions:\n",
        "                    raise ValueError(f\"Component '{component}' not found in input axes\")\n",
        "                transpose_indices.append(axis_positions[component])\n",
        "        else:\n",
        "            # Add position for simple axis\n",
        "            if axis not in axis_positions:\n",
        "                raise ValueError(f\"Axis '{axis}' not found in input axes\")\n",
        "            transpose_indices.append(axis_positions[axis])\n",
        "\n",
        "    # Calculate final shape (merging composite axes in output)\n",
        "    final_shape = []\n",
        "    i = 0\n",
        "\n",
        "    for axis, is_composite, components in output_axes:\n",
        "        if axis == '...':\n",
        "            # Add all ellipsis dimensions\n",
        "            final_shape.extend(ellipsis_dims)\n",
        "            i += ellipsis_len\n",
        "        elif is_composite:\n",
        "            # Calculate product of component dimensions\n",
        "            product = 1\n",
        "            for _ in components:\n",
        "                product *= initial_shape[transpose_indices[i]]\n",
        "                i += 1\n",
        "            final_shape.append(product)\n",
        "        else:\n",
        "            # Add dimension for simple axis\n",
        "            final_shape.append(initial_shape[transpose_indices[i]])\n",
        "            i += 1\n",
        "\n",
        "    return initial_shape, transpose_indices, final_shape\n",
        "\n",
        "\n",
        "def rearrange(tensor: np.ndarray, pattern: str, **axes_lengths) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Rearrange a tensor according to the given pattern, similar to einops.rearrange.\n",
        "    Optimized version with minimal intermediate operations.\n",
        "\n",
        "    Args:\n",
        "        tensor: Input tensor (numpy array)\n",
        "        pattern: Rearrangement pattern (e.g., 'b c h w -> b h w c')\n",
        "        **axes_lengths: Named sizes for axes (e.g., h=32, w=32)\n",
        "\n",
        "    Returns:\n",
        "        Rearranged tensor\n",
        "    \"\"\"\n",
        "    # Parse pattern (using cached results if pattern was seen before)\n",
        "    input_pattern, output_pattern = parse_pattern(pattern)\n",
        "    input_axes = parse_axes(input_pattern)\n",
        "    output_axes = parse_axes(output_pattern)\n",
        "\n",
        "    # Validate shapes and compute dimensions in one pass\n",
        "    dims_dict, ellipsis_dims, ellipsis_len = _get_dim_sizes(input_axes, tensor.shape, axes_lengths)\n",
        "\n",
        "    # Validate output axes\n",
        "    all_input_components = set()\n",
        "    for _, _, components in input_axes:\n",
        "        all_input_components.update(components)\n",
        "\n",
        "    for axis, _, components in output_axes:\n",
        "        if axis != '...':\n",
        "            for comp in components:\n",
        "                if comp != '...' and comp not in all_input_components and comp not in axes_lengths:\n",
        "                    raise ValueError(f\"Output component '{comp}' not found in input pattern or axes_lengths\")\n",
        "\n",
        "    # Compute all shapes and transpose indices in one pass\n",
        "    initial_shape, transpose_indices, final_shape = _compute_transpose_and_shapes(\n",
        "        input_axes, output_axes, tensor.shape, dims_dict, ellipsis_dims, ellipsis_len\n",
        "    )\n",
        "\n",
        "    # Special case: if no reshaping or transposition is needed, return original tensor\n",
        "    if tensor.shape == tuple(final_shape) and all(i == j for i, j in enumerate(transpose_indices)):\n",
        "        return tensor\n",
        "\n",
        "    # Special case: if only transposition is needed (no reshape), do it directly\n",
        "    if tensor.shape == tuple(initial_shape) and tuple(final_shape) == tuple(np.array(initial_shape)[transpose_indices]):\n",
        "        return np.transpose(tensor, transpose_indices)\n",
        "\n",
        "    # Otherwise do the full reshape-transpose-reshape operation\n",
        "    # Reshape to split axes\n",
        "    reshaped = tensor.reshape(initial_shape)\n",
        "\n",
        "    # Transpose to reorder dimensions\n",
        "    transposed = np.transpose(reshaped, transpose_indices)\n",
        "\n",
        "    # Reshape to merge axes\n",
        "    return transposed.reshape(final_shape)\n",
        "\n",
        "\n",
        "# Test functions with timing to show performance\n",
        "import time\n",
        "\n",
        "def time_test(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end = time.time()\n",
        "        print(f\"{func.__name__} completed in {(end-start)*1000:.2f} ms\")\n",
        "        return result\n",
        "    return wrapper\n",
        "\n",
        "@time_test\n",
        "def test_transpose():\n",
        "    x = np.random.rand(3, 4)\n",
        "    result = rearrange(x, 'h w -> w h')\n",
        "    assert result.shape == (4, 3)\n",
        "    assert np.allclose(result, x.T)\n",
        "    print(\"Transpose test passed\")\n",
        "\n",
        "@time_test\n",
        "def test_split_axis():\n",
        "    x = np.random.rand(12, 10)\n",
        "    result = rearrange(x, '(h w) c -> h w c', h=3, w=4)\n",
        "    assert result.shape == (3, 4, 10)\n",
        "    # Verify content is preserved\n",
        "    reshaped = x.reshape(3, 4, 10)\n",
        "    assert np.allclose(result, reshaped)\n",
        "    print(\"Split axis test passed\")\n",
        "\n",
        "@time_test\n",
        "def test_merge_axes():\n",
        "    x = np.random.rand(3, 4, 5)\n",
        "    result = rearrange(x, 'a b c -> (a b) c')\n",
        "    assert result.shape == (12, 5)\n",
        "    # Verify content is preserved\n",
        "    reshaped = x.reshape(12, 5)\n",
        "    assert np.allclose(result, reshaped)\n",
        "    print(\"Merge axes test passed\")\n",
        "\n",
        "@time_test\n",
        "def test_ellipsis():\n",
        "    x = np.random.rand(2, 3, 4, 5)\n",
        "    result = rearrange(x, '... h w -> ... (h w)')\n",
        "    assert result.shape == (2, 3, 20)\n",
        "    # Verify content is preserved\n",
        "    reshaped = x.reshape(2, 3, 20)\n",
        "    assert np.allclose(result, reshaped)\n",
        "    print(\"Ellipsis test passed\")\n",
        "\n",
        "@time_test\n",
        "def test_complex_pattern():\n",
        "    x = np.random.rand(2, 3, 4, 5)\n",
        "    result = rearrange(x, 'a b (c d) ... -> a (b c) ... d', d=1)\n",
        "    assert result.shape == (2, 12, 5, 1)\n",
        "    print(\"Complex pattern test passed\")\n",
        "\n",
        "@time_test\n",
        "def test_repeated_pattern():\n",
        "    \"\"\"Test the performance benefit of caching.\"\"\"\n",
        "    x = np.random.rand(10, 32, 32, 3)\n",
        "    # First call - parsing happens\n",
        "    result1 = rearrange(x, 'b h w c -> b c h w')\n",
        "    # Second call - should use cached parsing\n",
        "    result2 = rearrange(x, 'b h w c -> b c h w')\n",
        "    assert np.allclose(result1, result2)\n",
        "    print(\"Repeated pattern test passed\")\n",
        "\n",
        "def run_all_tests():\n",
        "    test_transpose()\n",
        "    test_split_axis()\n",
        "    test_merge_axes()\n",
        "    test_ellipsis()\n",
        "    test_complex_pattern()\n",
        "    test_repeated_pattern()\n",
        "    print(\"All tests passed!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_all_tests()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI4X1JUc2x1i",
        "outputId": "49eed669-7dba-4a58-cc02-662cb330b2d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transpose test passed\n",
            "test_transpose completed in 20.46 ms\n",
            "Split axis test passed\n",
            "test_split_axis completed in 0.38 ms\n",
            "Merge axes test passed\n",
            "test_merge_axes completed in 0.39 ms\n",
            "Ellipsis test passed\n",
            "test_ellipsis completed in 0.24 ms\n",
            "Complex pattern test passed\n",
            "test_complex_pattern completed in 0.11 ms\n",
            "Repeated pattern test passed\n",
            "test_repeated_pattern completed in 1.95 ms\n",
            "All tests passed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "91k1BU6B26yC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}