{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTaxbzJgyRzseLHUtDwVZn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/atharva753/SarvamLLM_Assignment-2/blob/main/Unit_tests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile your_module.py\n",
        "import re\n",
        "import numpy as np\n",
        "from typing import Any\n",
        "\n",
        "def rearrange(tensor: np.ndarray, pattern: str, **axes_lengths: int) -> np.ndarray:\n",
        "    def parse_side(side: str) -> list:\n",
        "        tokens = re.findall(r'\\([^)]*\\)|\\.\\.\\.|[^\\s]+', side)\n",
        "        parsed = []\n",
        "        for token in tokens:\n",
        "            if token == '...':\n",
        "                parsed.append('...')\n",
        "            elif token.startswith('('):\n",
        "                inner = token[1:-1].strip()\n",
        "                if not inner:\n",
        "                    raise ValueError(\"Empty group '()' is not allowed in the pattern.\")\n",
        "                parsed.append(inner.split())\n",
        "            else:\n",
        "                parsed.append(token)\n",
        "        return parsed\n",
        "    try:\n",
        "        input_pattern, output_pattern = pattern.split(\"->\")\n",
        "    except Exception:\n",
        "        raise ValueError(\"Invalid pattern: missing '->'\")\n",
        "    input_pattern = input_pattern.strip()\n",
        "    output_pattern = output_pattern.strip()\n",
        "    input_tokens = parse_side(input_pattern)\n",
        "    output_tokens = parse_side(output_pattern)\n",
        "    # Build raw input tokens list (group tokens count as one)\n",
        "    raw_input = []\n",
        "    for tok in input_tokens:\n",
        "        if tok == '...':\n",
        "            raw_input.extend([f\"__batch_{i}\" for i in range(tensor.ndim - sum(1 for t in input_tokens if t != '...'))])\n",
        "        elif isinstance(tok, list):\n",
        "            raw_input.append(tok)\n",
        "        else:\n",
        "            raw_input.append(tok)\n",
        "    if len(raw_input) != tensor.ndim:\n",
        "        raise ValueError(\"Parsed input token count does not match tensor dimensions.\")\n",
        "    # Process raw_input to build flat mapping. For group tokens, process the merged axis.\n",
        "    flat_input = []\n",
        "    tensor_axes = []\n",
        "    t_ptr = 0\n",
        "    for token in raw_input:\n",
        "        if isinstance(token, list):\n",
        "            merged_size = tensor.shape[t_ptr]\n",
        "            factors = {}\n",
        "            for name in token:\n",
        "                factors[name] = axes_lengths[name] if name in axes_lengths else None\n",
        "            unknowns = [n for n,v in factors.items() if v is None]\n",
        "            prod_known = 1\n",
        "            for v in factors.values():\n",
        "                if v is not None:\n",
        "                    prod_known *= v\n",
        "            if len(unknowns) > 1:\n",
        "                raise ValueError(f\"Cannot infer more than one missing axis length in group {token}\")\n",
        "            if unknowns:\n",
        "                missing = unknowns[0]\n",
        "                if merged_size % prod_known != 0:\n",
        "                    raise ValueError(f\"Inferred size for axis '{missing}' does not divide merged axis size\")\n",
        "                factors[missing] = merged_size // prod_known\n",
        "            else:\n",
        "                if prod_known != merged_size:\n",
        "                    raise ValueError(\"Provided axes lengths do not match the merged axis size.\")\n",
        "            for name in token:\n",
        "                flat_input.append(name)\n",
        "                tensor_axes.append(factors[name])\n",
        "            t_ptr += 1\n",
        "        else:\n",
        "            flat_input.append(token)\n",
        "            tensor_axes.append(tensor.shape[t_ptr])\n",
        "            t_ptr += 1\n",
        "    # Build input mapping.\n",
        "    input_mapping = {}\n",
        "    for idx, label in enumerate(flat_input):\n",
        "        input_mapping.setdefault(label, []).append(idx)\n",
        "    # Process output tokens. For groups in output, keep as list.\n",
        "    output_flat = []\n",
        "    output_groups = []\n",
        "    for tok in output_tokens:\n",
        "        if tok == '...':\n",
        "            batch = [lbl for lbl in flat_input if lbl.startswith(\"__batch_\")]\n",
        "            output_flat.extend(batch)\n",
        "        elif isinstance(tok, list):\n",
        "            start = len(output_flat)\n",
        "            output_flat.extend(tok)\n",
        "            output_groups.append((start, len(tok)))\n",
        "        else:\n",
        "            output_flat.append(tok)\n",
        "    perm = []\n",
        "    used = set()\n",
        "    for label in output_flat:\n",
        "        if label in input_mapping:\n",
        "            indices = input_mapping[label]\n",
        "            chosen = None\n",
        "            for i in indices:\n",
        "                if i not in used:\n",
        "                    chosen = i\n",
        "                    used.add(i)\n",
        "                    break\n",
        "            if chosen is None:\n",
        "                raise ValueError(f\"Could not resolve label '{label}'\")\n",
        "            perm.append(chosen)\n",
        "        else:\n",
        "            # If output label not found, try to resolve a '1' token.\n",
        "            ones = [i for i, lab in enumerate(flat_input) if lab == '1' and i not in used]\n",
        "            if ones:\n",
        "                chosen = ones[0]\n",
        "                used.add(chosen)\n",
        "                perm.append(chosen)\n",
        "            else:\n",
        "                raise ValueError(f\"Output label '{label}' not found in input pattern.\")\n",
        "    remaining = [i for i in range(len(flat_input)) if i not in used]\n",
        "    perm.extend(remaining)\n",
        "    transposed = np.transpose(tensor, axes=perm)\n",
        "    new_shape = [tensor_axes[i] for i in perm]\n",
        "    out_tensor = transposed\n",
        "    for i, label in enumerate(output_flat):\n",
        "        if flat_input[perm[i]] == '1' and label not in input_mapping:\n",
        "            if label not in axes_lengths:\n",
        "                raise KeyError(f\"Missing axes length for repeated singleton axis '{label}'\")\n",
        "            factor = axes_lengths[label]\n",
        "            if new_shape[i] != 1:\n",
        "                raise ValueError(\"Attempt to repeat a non-singleton axis\")\n",
        "            out_tensor = np.repeat(out_tensor, factor, axis=i)\n",
        "            new_shape[i] = factor\n",
        "    shift = 0\n",
        "    for start, length in output_groups:\n",
        "        real_start = start - shift\n",
        "        if real_start + length > len(new_shape):\n",
        "            raise ValueError(\"Merging group indices out of bounds.\")\n",
        "        prod = 1\n",
        "        for j in range(real_start, real_start+length):\n",
        "            prod *= new_shape[j]\n",
        "        pre = new_shape[:real_start]\n",
        "        post = new_shape[real_start+length:]\n",
        "        new_shape = pre + [prod] + post\n",
        "        out_tensor = out_tensor.reshape(new_shape)\n",
        "        shift += length - 1\n",
        "    return out_tensor\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import numpy as np\n",
        "    x = np.random.rand(3, 4)\n",
        "    print(rearrange(x, \"h w -> w h\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0Pa0YmPD8ie",
        "outputId": "2cb0039e-0818-438f-8c99-4ec113f03ee1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting your_module.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import unittest\n",
        "from your_module import rearrange\n",
        "\n",
        "class TestRearrangeFunction(unittest.TestCase):\n",
        "    def test_transpose(self):\n",
        "        x = np.arange(12).reshape(3, 4)\n",
        "        result = rearrange(x, \"h w -> w h\")\n",
        "        expected = np.transpose(x)\n",
        "        np.testing.assert_array_equal(result, expected)\n",
        "    def test_split_axis(self):\n",
        "        x = np.arange(120).reshape(12, 10)\n",
        "        result = rearrange(x, \"(h w) c -> h w c\", h=3)\n",
        "        expected = np.reshape(x, (3, 4, 10))\n",
        "        np.testing.assert_array_equal(result, expected)\n",
        "    def test_merge_axes(self):\n",
        "        x = np.arange(60).reshape(3, 4, 5)\n",
        "        result = rearrange(x, \"a b c -> (a b) c\")\n",
        "        expected = np.reshape(x, (3 * 4, 5))\n",
        "        np.testing.assert_array_equal(result, expected)\n",
        "    def test_repeat_axis(self):\n",
        "        x = np.arange(15).reshape(3, 1, 5)\n",
        "        result = rearrange(x, \"a 1 c -> a b c\", b=4)\n",
        "        expected = np.repeat(x, 4, axis=1)\n",
        "        np.testing.assert_array_equal(result, expected)\n",
        "    def test_batch_dimensions(self):\n",
        "        x = np.arange(2 * 3 * 4 * 5).reshape(2, 3, 4, 5)\n",
        "        result = rearrange(x, \"... h w -> ... (h w)\")\n",
        "        expected = x.reshape(2, 3, 4*5)\n",
        "        np.testing.assert_array_equal(result, expected)\n",
        "    def test_invalid_pattern(self):\n",
        "        x = np.arange(6).reshape(2, 3)\n",
        "        with self.assertRaises(ValueError):\n",
        "            rearrange(x, \"a b -> a b c\")\n",
        "    def test_missing_axes_length(self):\n",
        "        x = np.arange(120).reshape(12, 10)\n",
        "        with self.assertRaises(ValueError):\n",
        "            rearrange(x, \"(h w) c -> h w c\")\n",
        "    def test_extra_axes_length(self):\n",
        "        x = np.arange(12).reshape(3, 4)\n",
        "        with self.assertRaises(ValueError):\n",
        "            rearrange(x, \"h w -> w h\", x=3)\n",
        "    def test_complex_combined_operations(self):\n",
        "        x = np.arange(6 * 4 * 5).reshape(6, 4, 5)\n",
        "        result = rearrange(x, \"(a b) c d -> a (c d) b\", a=2)\n",
        "        expected = x.reshape(2, -1, 3)\n",
        "        np.testing.assert_array_equal(result, expected)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=[''], exit=False)\n"
      ],
      "metadata": {
        "id": "Hcq77NePG0Cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yO6Wkk0bHECo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}